{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235bbad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 20:28:14.537365: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 20:28:14.846972: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-24 20:28:14.846991: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-24 20:28:15.700168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-24 20:28:15.700224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-24 20:28:15.700230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da136d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    '''\n",
    "    This Neural Network class builds the network's nodes and layers.\n",
    "    It using stochastic gradient to train the training data.\n",
    "    Compute the trained weights and biases.\n",
    "    Compute evaluation on testing data.\n",
    "    '''\n",
    "    def __init__(self, net):\n",
    "        # Builds the network with the net's length is the layer \n",
    "        # and elements' value as number of nodes\n",
    "        self.layers = len(net)\n",
    "        self.net = net\n",
    "        self.biases = [np.random.randn(k,1) for k in net[1:]]\n",
    "        self.weights = [np.random.randn(j,k) for k,j in zip(net[:-1], net[1:])]\n",
    "        self.c = []\n",
    "        self.iterate = 0\n",
    "    \n",
    "    def SGD(self, data , epochs = 15, mini_batch_size = 10, lr = 1.0):\n",
    "        # SGD randomly shuffle the training data\n",
    "        # split training data into batches with mini batch size\n",
    "        # train each batch in batches and update the weights and biases\n",
    "        for x in range(epochs):\n",
    "            np.random.shuffle(data)\n",
    "            batches = [data[i:i+mini_batch_size] for i in range(0,len(data),mini_batch_size)]\n",
    "            for batch in batches:\n",
    "                self.mini_batch_update(batch,lr)\n",
    "            print(\"epochs: {}/{}\".format(x+1, epochs))\n",
    "                \n",
    "    def mini_batch_update(self, batch, lr):\n",
    "        # Train each batch in batches and update the weights and biases\n",
    "        # Compute the gradient for each weights and biases\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # For each training data in batch compute gradient using the backpropagate \n",
    "        # Sum the gradient for each weights and biases\n",
    "        for i in range(len(batch)):\n",
    "            input_node = batch[i][0]\n",
    "            output_node = batch[i][1]\n",
    "            d_w, d_b = self.backpropagate(input_node, output_node)  \n",
    "            delta_w = [(w1+w2)for w1,w2 in zip(delta_w,d_w)]\n",
    "            delta_b = [(b1+b2) for b1,b2 in zip(delta_b, d_b)]\n",
    "        # Update the weights and biases with learning rate and the gradient\n",
    "        self.weights = [(w-((lr/len(batch))*d_w)) for w,d_w in zip(self.weights,delta_w)]\n",
    "        self.biases = [(b-((lr/len(batch))*d_b)) for b, d_b in zip(self.biases, delta_b)] \n",
    "\n",
    "    def backpropagate(self, x, y):\n",
    "        # Take in a single training data\n",
    "        # backpropagate\n",
    "        # output gradient from a single training data\n",
    "        d_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        d_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        z_nodes, a_nodes = self.feedforward(x) # output/activation nodes\n",
    "        output_e = self.delta_cost(a_nodes[-1], y)*self.d_sigmoid(z_nodes[-1]) # output error\n",
    "        d_w[-1] = np.dot(output_e, a_nodes[-2].transpose()) \n",
    "        d_b[-1] = output_e\n",
    "        \n",
    "        for l in range(2,self.layers):\n",
    "            output_e = np.dot(self.weights[-l+1].transpose(),output_e)*self.d_sigmoid(z_nodes[-l])\n",
    "            d_w[-l] = np.dot(output_e, a_nodes[-l-1].transpose())\n",
    "            d_b[-l] = output_e\n",
    "        self.iterate += 1\n",
    "        return d_w, d_b \n",
    "                  \n",
    "    def feedforward(self, input_node):\n",
    "        # Take in a training example\n",
    "        # output the z and a for each layer\n",
    "        node = input_node\n",
    "        z = []\n",
    "        a = [node]\n",
    "        for w,b in zip(self.weights, self.biases):\n",
    "            node = np.dot(w, node)+b\n",
    "            z.append(node)\n",
    "            node = self.sigmoid(node)\n",
    "            a.append(node)\n",
    "        return z, a\n",
    "    \n",
    "    def cost(self, output_node, label):\n",
    "        # Cost/Loss\n",
    "        co = 1/2*(output_node-label)**2\n",
    "        if (self.iterate%100) == 0:\n",
    "            print(co)\n",
    "        self.c.append(co.mean())\n",
    "    \n",
    "    def delta_cost(self,output_node, label):\n",
    "        error = (output_node-label)\n",
    "        return error\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        z = np.clip(z, -500, 500)\n",
    "        a = 1.0/(1.0+np.exp(-z))\n",
    "        return a\n",
    "    \n",
    "    def d_sigmoid(self, z):\n",
    "        d_a = self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "        return d_a\n",
    "    \n",
    "    def get_wb(self):\n",
    "        return self.weights, self.biases\n",
    "    \n",
    "    def get_cost(self):\n",
    "        return self.c\n",
    "    \n",
    "    def plot_cost(self):\n",
    "        pass\n",
    "    \n",
    "    def evaluation(self, data):\n",
    "        correct = 0\n",
    "        for d in data:\n",
    "            x = d[0]\n",
    "            y = d[1]\n",
    "            z,a = self.feedforward(x)\n",
    "            output_node = a[-1]\n",
    "            \n",
    "            if np.argmax(output_node) == np.argmax(y):\n",
    "                correct +=1\n",
    "        print(\"accuracy: \", correct, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348b361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7a83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros((train_X.shape[0], train_X.shape[1]**2))\n",
    "train_y = np.zeros((train_Y.shape[0], 10))\n",
    "test_x = np.zeros((test_X.shape[0], test_X.shape[1]**2)) \n",
    "test_y = np.zeros((test_Y.shape[0], 10))\n",
    "\n",
    "\n",
    "for i in range(len(train_x)):\n",
    "    x = np.array([train_X[i].ravel()])\n",
    "    x = np.ma.log2(x)\n",
    "    train_x[i] = x\n",
    "\n",
    "for i in range(len(train_Y)):\n",
    "    temp = np.zeros(10)\n",
    "    temp[train_Y[i]] = 1\n",
    "    train_y[i] = temp\n",
    "training_data = [[np.expand_dims(x,1),np.expand_dims(y,1)] for x,y in zip(train_x,train_y)]\n",
    "\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    x = np.array([test_X[i].ravel()])\n",
    "    x = np.ma.log2(x)\n",
    "    test_x[i] = x\n",
    "\n",
    "for i in range(len(test_Y)):\n",
    "    temp = np.zeros(10)\n",
    "    temp[test_Y[i]] = 1\n",
    "    test_y[i] = temp\n",
    "test_data = [[np.expand_dims(x,1),np.expand_dims(y,1)] for x,y in zip(test_x,test_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24684b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [784,25,25,10]\n",
    "epochs = 10\n",
    "mini_batch_size = 10\n",
    "learing_rate = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9aa075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1/10\n",
      "epochs: 2/10\n",
      "epochs: 3/10\n",
      "epochs: 4/10\n",
      "epochs: 5/10\n",
      "epochs: 6/10\n",
      "epochs: 7/10\n",
      "epochs: 8/10\n",
      "epochs: 9/10\n",
      "epochs: 10/10\n",
      "accuracy:  9039 10000\n"
     ]
    }
   ],
   "source": [
    "handwritten_digit_network = Neural_Network(network)\n",
    "handwritten_digit_network.SGD(training_data, epochs, mini_batch_size, learing_rate)\n",
    "handwritten_digit_network.evaluation(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a39c1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  9179 10000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(test_data)):\n",
    "    x = test_data[i][0]\n",
    "    y = test_data[i][1]\n",
    "    a,z = handwritten_digit_network.feedforward(x)\n",
    "    x_out = a[-1]\n",
    "    if np.argmax(x_out) == np.argmax(y):\n",
    "        correct +=1\n",
    "print(\"accuracy: \", correct, len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
