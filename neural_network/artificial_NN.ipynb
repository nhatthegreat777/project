{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad569e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 11:50:45.677042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 11:50:45.924436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-19 11:50:45.924465: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-19 11:50:46.812556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-19 11:50:46.812629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-19 11:50:46.812637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d357f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self, net):\n",
    "        self.layers = len(net)\n",
    "        self.net = net\n",
    "        self.biases = [10*np.random.randn(1,k) for k in net[1:]]\n",
    "        self.weights = [10*np.random.randn(j,k) for k,j in zip(net[:-1], net[1:])]\n",
    "        self.c = []\n",
    "        self.iterate = 0\n",
    "        \n",
    "    def get_wb(self):\n",
    "        return self.weights, self.biases\n",
    "    \n",
    "    def SDG(self, data , epochs = 15, mini_batch_size = 500, lr = 0.03, testing_data=False):\n",
    "        if testing_data:\n",
    "            return self.evaluation(data)\n",
    "        batches = [data[i:i+mini_batch_size] for i in range(0,len(data),mini_batch_size)]\n",
    "        for x in range(epochs):\n",
    "            np.random.shuffle(data)\n",
    "            for batch in batches:\n",
    "                self.mini_batch_update(batch,lr)\n",
    "            print(\"epochs: {}/{}\".format(x+1, epochs))\n",
    "\n",
    "    def mini_batch_update(self, batch, lr):\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        for i in range(len(batch)):\n",
    "            input_node = batch[i][0]\n",
    "            output_node = batch[i][1]\n",
    "            d_w, d_b = self.gradient_descent(input_node, output_node)\n",
    "            delta_w = [w1+w2 for w1,w2 in zip(delta_w,d_w)]\n",
    "            delta_b = [b1+b2 for b1,b2 in zip(delta_b, d_b)]\n",
    "\n",
    "        self.weights = [w-((lr/len(batch))*d_w) for w,d_w in zip(self.weights,delta_w)]\n",
    "        self.biases = [b-((lr/len(batch))*d_b) for b, d_b in zip(self.biases, delta_b)]    \n",
    "\n",
    "    def gradient_descent(self, x, y):\n",
    "        # Take in a single training example\n",
    "        # back propagate\n",
    "        d_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        d_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        z_nodes, a_nodes = self.feedforward(x)\n",
    "        if (self.iterate %100 ==0):\n",
    "            self.cost(a_nodes[-1], y)\n",
    "        output_e = self.delta_cost(a_nodes[-1], y)*self.d_sigmoid(z_nodes[-1])\n",
    "        d_w[-1] = np.dot(output_e.transpose(), a_nodes[-2])\n",
    "        d_b[-1] = output_e\n",
    "        \n",
    "        for l in range(2,self.layers):\n",
    "            output_e = np.dot(output_e, self.weights[-l+1])*self.d_sigmoid(z_nodes[-l])\n",
    "            d_w[-l] = np.dot(output_e.transpose(), a_nodes[-l-1])\n",
    "            d_b[-l] = output_e\n",
    "        self.iterate += 1\n",
    "        return d_w, d_b \n",
    "                  \n",
    "    def feedforward(self, input_node):\n",
    "        # Take in a training example\n",
    "        # output the z and a for each layer\n",
    "        node = np.expand_dims(input_node,0)\n",
    "        z = []\n",
    "        a = [node]\n",
    "        for w,b in zip(self.weights, self.biases):\n",
    "            node = np.dot(node, w.transpose())+b\n",
    "            z.append(node)\n",
    "            node = self.sigmoid(node)\n",
    "            a.append(node)\n",
    "        return z, a\n",
    "    \n",
    "    def cost(self, output_node, label):\n",
    "        co = 1/2*(output_node-label)**2\n",
    "        co = co.mean()\n",
    "        print(\"Cost:\", co)\n",
    "        self.c.append(co)\n",
    "    \n",
    "    def get_cost(self):\n",
    "        return self.c\n",
    "    \n",
    "    def delta_cost(self,output_node, label):\n",
    "        error = (output_node-label)\n",
    "        return error\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        a = 1/(1+np.exp(-z, dtype=np.float128))\n",
    "        return a\n",
    "    \n",
    "    def d_sigmoid(self, z):\n",
    "        d_a = np.exp(-z, dtype=np.float128)/((1+np.exp(-z, dtype=np.float128))**2)\n",
    "        return d_a\n",
    "    \n",
    "    def plot_cost(self):\n",
    "        print(\"len: {}\", len(self.c))\n",
    "        plt.plot(len(self.c), self.c, 'ro')\n",
    "        plt.show()\n",
    "        \n",
    "    def evaluation(self, data):\n",
    "        correct = 0\n",
    "        wrong = 0\n",
    "        for x,y in zip(data[0], data[1]):\n",
    "            z,a = self.feedforward(x)\n",
    "            y_prime = np.argmax(a[-1])\n",
    "            y = np.argmax(y)\n",
    "\n",
    "            if y_prime == y:\n",
    "                correct +=1\n",
    "            else:\n",
    "                wrong += 1\n",
    "        accuracy = correct/len(data)\n",
    "        print(\"correct prediction: {} Accuracy: {}\".format(correct, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348b361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d7a83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros((train_X.shape[0], train_X.shape[1]**2))\n",
    "train_y = np.zeros((train_Y.shape[0], 10))\n",
    "test_x = np.zeros((test_X.shape[0], test_X.shape[1]**2)) \n",
    "test_y = np.zeros((test_Y.shape[0], 10))\n",
    "\n",
    "for i in range(len(train_x)):\n",
    "    x = np.array([train_X[i].ravel()])\n",
    "    x = np.ma.log2(x)\n",
    "    x = x.filled(0)\n",
    "    train_x[i] = x\n",
    "\n",
    "for i in range(len(train_Y)):\n",
    "    y = np.zeros(10)\n",
    "    y[train_Y[i]] = 1\n",
    "    train_y[i] = y\n",
    "training_data = [[x,y] for x,y in zip(train_x,train_y)]\n",
    "\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    x = np.array([train_X[i].ravel()])\n",
    "    x = np.ma.log2(x)\n",
    "    x = x.filled(0)\n",
    "    test_x[i] = x\n",
    "\n",
    "for i in range(len(test_Y)):\n",
    "    y = np.zeros(10)\n",
    "    y[test_Y[i]] = 1\n",
    "    test_y[i] = y\n",
    "test_data = [[x,y] for x,y in zip(test_x,test_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24684b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [784,25,25,10]\n",
    "epochs = 15\n",
    "mini_batch_size = 500\n",
    "learing_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69a48eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: batch 500\n",
      "Cost: 0.30000000097066909955\n",
      "Cost: 0.28383897980598498902\n",
      "Cost: 0.2500651422144861969\n",
      "Cost: 0.24958202606435451768\n",
      "Cost: 0.29949935109270326436\n",
      "length: batch 500\n",
      "Cost: 0.24141827508577839336\n",
      "Cost: 0.20006890380292941484\n",
      "Cost: 0.1999999988909977234\n",
      "Cost: 0.19999998724650653644\n",
      "Cost: 0.3018635373145998052\n",
      "length: batch 500\n",
      "Cost: 0.25000002496895018633\n",
      "Cost: 0.29999952494999025586\n",
      "Cost: 0.3991733791198748221\n",
      "Cost: 0.2499951153864719051\n",
      "Cost: 0.19997626150773648037\n",
      "length: batch 500\n",
      "Cost: 0.2999316730433741822\n",
      "Cost: 0.2986882174632079725\n",
      "Cost: 0.20128640499910809408\n",
      "Cost: 0.29999294726976960583\n",
      "Cost: 0.30071834706304307594\n",
      "length: batch 500\n",
      "Cost: 0.20133308283199858589\n",
      "Cost: 0.19999987612536577027\n",
      "Cost: 0.34034403046565204646\n",
      "Cost: 0.29969326065557724375\n",
      "Cost: 0.199999998072386325\n",
      "length: batch 500\n",
      "Cost: 0.20000002607042289804\n",
      "Cost: 0.24998882962506380209\n",
      "Cost: 0.14999614156769280115\n",
      "Cost: 0.34952416961125419795\n",
      "Cost: 0.19999999999999507852\n",
      "length: batch 500\n",
      "Cost: 0.29303770877542969678\n",
      "Cost: 0.389576212481636014\n",
      "Cost: 0.19999999988858150906\n",
      "Cost: 0.20776603263151392453\n",
      "Cost: 0.20010973593199649591\n",
      "length: batch 500\n",
      "Cost: 0.23277341489540009822\n",
      "Cost: 0.2999999993051311048\n",
      "Cost: 0.199999999999804245\n",
      "Cost: 0.30422607910027248015\n",
      "Cost: 0.29427058615071406586\n",
      "length: batch 500\n",
      "Cost: 0.29999992241335875483\n",
      "Cost: 0.19925981870786637254\n",
      "Cost: 0.3499983363155797596\n",
      "Cost: 0.2999999455863409609\n",
      "Cost: 0.3006348323249527043\n",
      "length: batch 500\n",
      "Cost: 0.29999664741252947457\n",
      "Cost: 0.29999972113265942387\n",
      "Cost: 0.3499927744368329956\n",
      "Cost: 0.2754447389488136272\n",
      "Cost: 0.25000001468092556314\n",
      "length: batch 500\n",
      "Cost: 0.24996728499186522104\n",
      "Cost: 0.22736880087370329999\n",
      "Cost: 0.3022104162730661705\n",
      "Cost: 0.2000002837645259948\n",
      "Cost: 0.29969558838125447456\n",
      "length: batch 500\n",
      "Cost: 0.25000006530785681227\n",
      "Cost: 0.2500050591128427457\n",
      "Cost: 0.2990702879946683512\n",
      "Cost: 0.30002536971912032316\n",
      "Cost: 0.31725863799289426696\n",
      "length: batch 500\n",
      "Cost: 0.24324418048149096713\n",
      "Cost: 0.20524735602578233482\n",
      "Cost: 0.30001907164074805362\n",
      "Cost: 0.18826878392024916591\n",
      "Cost: 0.34737472791890322148\n",
      "length: batch 500\n",
      "Cost: 0.20027534137674333046\n",
      "Cost: 0.20000000859344674768\n",
      "Cost: 0.20000000001019118019\n",
      "Cost: 0.27237895804890539933\n",
      "Cost: 0.30307915334460548964\n",
      "length: batch 500\n",
      "Cost: 0.19999999999994578535\n",
      "Cost: 0.24634954583812857427\n",
      "Cost: 0.14999739407396761189\n",
      "Cost: 0.29999996283036237473\n",
      "Cost: 0.29959400540801363078\n",
      "length: batch 500\n",
      "Cost: 0.2999999999977838388\n",
      "Cost: 0.28733699853209151363\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6992/2238652374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhandwritten_digit_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhandwritten_digit_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearing_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6992/1214744258.py\u001b[0m in \u001b[0;36mSDG\u001b[0;34m(self, data, epochs, mini_batch_size, lr, testing_data)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmini_batch_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs: {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6992/1214744258.py\u001b[0m in \u001b[0;36mmini_batch_update\u001b[0;34m(self, batch, lr)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0minput_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moutput_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0md_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mdelta_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mdelta_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6992/1214744258.py\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moutput_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0md_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0md_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "handwritten_digit_network = Neural_Network(network)\n",
    "\n",
    "handwritten_digit_network.SDG(training_data, epochs, mini_batch_size, learing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "640d7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = handwritten_digit_network.get_wb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20a259a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  116 1000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(test_data[:1000])):\n",
    "    x = test_data[i][0]\n",
    "    y = test_data[i][1]\n",
    "    a,z = handwritten_digit_network.feedforward(x)\n",
    "    x_out = a[-1]\n",
    "    if np.argmax(x_out) == np.argmax(y):\n",
    "        correct +=1\n",
    "print(\"accuracy: \", correct, len(test_data[:1000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
